#!/bin/bash
#SBATCH --job-name=simclr1            # Job name
#SBATCH --ntasks=4                    # Run on a single CPU
#SBATCH --partition=gpu               # GPU partition
#SBATCH --gpus=a100:1                 # A100 gpu
#SBATCH --mem=32gb                    # Job memory request
#SBATCH --time=24:00:00               # Time limit hrs:min:sec
#SBATCH --output=simclr1_out_%j.log   # Standard output and error log
pwd; hostname; date

Nshot_list="1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 32 64 128 256 512 1024 -1"
Train_size_list="1 10 100 200 500 1024 2048 4096 8192 16384 32768 -1"

ml git pytorch
# experiment set 1
for ((i = 0 ; i < 2 ; i++)); do
    for nshot in $Nshot_list; do
        python3 main.py --batch_size 512 --k 1 --epochs 5 --nshots $nshot
    done
done

echo
echo

# experiment set 2
for ((i = 0 ; i < 2 ; i++)); do
    for size in $Train_size_list; do
        python3 main.py --batch_size 512 --k 1 --epochs 5 --nshots 10 --train_size $size
    done
done

date
